{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev-work: hashing as parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system dependecies\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# library dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "## biopython\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SearchIO\n",
    "\n",
    "## pyhmmer\n",
    "import pyhmmer\n",
    "\n",
    "## datasketch\n",
    "from datasketch import MinHash\n",
    "\n",
    "# local dependencies/utils\n",
    "\n",
    "## Paths\n",
    "PFAM_PATH = Path(\"/Users/humoodalanzi/pfam/Pfam-A.hmm\")\n",
    "ID_DB_PATH = Path(\"/Users/humoodalanzi/pfam/proteins_id.zip\")\n",
    "#probably need path of unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meso_output = os.path.abspath(os.path.join('..', 'examples', \"meso_output.domtblout\"))\n",
    "thermo_output = os.path.abspath(os.path.join('..', 'examples', \"thermo_output.domtblout\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [dev-HA_pyhmmer.ipynb](./dev-HA_pyhmmer.ipynb), I developed the below function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hmmer(\n",
    "        seqs: pd.core.frame.DataFrame,\n",
    "        input_file: str,\n",
    "        hmm: str,\n",
    "        output_file: str,\n",
    "        cpu: int = 4,\n",
    "        prefetching=False,\n",
    "        save_out=False,\n",
    "        eval_con: float = 1e-10):\n",
    "    \"\"\"\n",
    "    Runs HMMER's hmmscan program on a set of input sequences using HMMs from a given database.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seqs : pandas.core.frame.DataFrame\n",
    "        A dataframe with string amino acid sequences in a 'seq' column.\n",
    "    input_file : str\n",
    "        Path to the input sequence file.\n",
    "    hmm : str\n",
    "        Path to the HMM database.\n",
    "    output_file : str\n",
    "        Path to the output file.\n",
    "    cpu : int, optional\n",
    "        The number of CPUs to use. Default is 4.\n",
    "    prefetching : bool, optional\n",
    "        Whether to use prefetching for faster search. Default is False.\n",
    "    save_out : bool, optional\n",
    "        Whether to save the output to file. Default is False.\n",
    "    eval_con : float, optional\n",
    "        E-value threshold for domain reporting. Default is 1e-10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pyhmmer.plan7.TopHits or None\n",
    "        The output hits if `save_out` is False, otherwise None.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the input dataframe is empty.\n",
    "    AttributeError\n",
    "        If any of the sequences are invalid.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function runs HMMER's hmmscan program on a set of input sequences\n",
    "    using HMMs from a given database.\n",
    "    The function supports two modes: normal mode and prefetching mode.\n",
    "    In normal mode, the HMMs are pressed and stored in a directory before execution.\n",
    "    In prefetching mode, the HMMs are kept in memory for faster search.\n",
    "    \"\"\"\n",
    "    # generate meso and thermo files\n",
    "    read_seq(seqs, input_file)\n",
    "\n",
    "    # place files into HMMER/pfam\n",
    "    run_pyhmmer(\n",
    "        hmm,\n",
    "        input_file,\n",
    "        output_file,\n",
    "        cpu,\n",
    "        prefetching,\n",
    "        save_out,\n",
    "        eval_con)\n",
    "\n",
    "\n",
    "def read_seq(lists: pd.core.frame.DataFrame, inputname: str = \"input\"):\n",
    "    \"\"\"\n",
    "    Returns a list of SeqRecord objects and creates a corresponding input Fasta of them\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    list : pandas.core.frame.DataFrame\n",
    "        a dataframe with string amino acid sequences in a 'seq' column\n",
    "    input name : str, default = 'input'\n",
    "        a name for the input fasta file\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    file : TextIOWrapper\n",
    "        the input fasta file created from the list of SeqRecord objects\n",
    "\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError :\n",
    "        if the input dataframe is empty\n",
    "    AttributeError :\n",
    "        if any of the sequences are invalid\n",
    "    \"\"\"\n",
    "    # check if input is empty\n",
    "    if lists.empty:\n",
    "        raise ValueError(\"Input dataframe is empty\")\n",
    "\n",
    "    # check if sequences are valid\n",
    "    for seq in lists['protein_seq']:\n",
    "        try:\n",
    "            Seq(seq)\n",
    "        except BaseException as exc:\n",
    "            raise AttributeError(\"Invalid sequence\") from exc\n",
    "\n",
    "    # function\n",
    "    records = []\n",
    "    for index, seq in lists.itertuples():\n",
    "        try:\n",
    "            record = SeqRecord(Seq(seq), id=str(index))\n",
    "            records.append(record)\n",
    "        except AttributeError as exc:\n",
    "            raise AttributeError(f\"Invalid sequence: {seq}\") from exc\n",
    "\n",
    "    # raise error if seq not valid\n",
    "    if not records:\n",
    "        raise AttributeError(\"No valid sequences found in input\")\n",
    "\n",
    "    with open(f\"{inputname}.fasta\", \"w\", encoding=\"utf-8\") as file:\n",
    "        SeqIO.write(records, file, \"fasta\")\n",
    "    return file\n",
    "\n",
    "\n",
    "def run_pyhmmer(\n",
    "        hmmdb: str,\n",
    "        input_file: str,\n",
    "        output_file: str,\n",
    "        cpu: int = 4,\n",
    "        prefetching=False,\n",
    "        save_out=False,\n",
    "        eval_con: float = 1e-10):\n",
    "    \"\"\"\n",
    "    Run hmmscan on input sequences with HMMs from a database.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hmmdb : str\n",
    "        Path to the HMM database.\n",
    "    input_file : str\n",
    "        Path to the input sequence file.\n",
    "    output_file : str\n",
    "        Path to the output file.\n",
    "    cpu : int, optional\n",
    "        The number of CPUs to use. Default is 4.\n",
    "    prefetching : bool, optional\n",
    "        Whether to use prefetching for faster search. Default is False.\n",
    "    save_out : bool, optional\n",
    "        Whether to save the output to file. Default is False.\n",
    "    eval_con : float, optional\n",
    "        E-value threshold for domain reporting. Default is 1e-10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_hits : pyhmmer.plan7.TopHits or None\n",
    "        The output hits if `save_out` is False, otherwise None.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function runs HMMER's hmmscan program on a set of input sequences\n",
    "    using HMMs from a given database.\n",
    "    The function supports two modes: normal mode and prefetching mode.\n",
    "    In normal mode, the HMMs are pressed and stored in a directory before execution.\n",
    "    In prefetching mode, the HMMs are kept in memory for faster search.\n",
    "    \"\"\"\n",
    "    # Create hmms\n",
    "    hmms = pyhmmer.plan7.HMMFile(hmmdb)\n",
    "    # press hmms and store them in the pfam data folder or w/e destination\n",
    "    if not os.path.exists(\n",
    "        os.path.join(\n",
    "            \"../data/pfam/\",\n",
    "            os.path.basename(hmmdb) +\n",
    "            \".h3m\")):\n",
    "        pyhmmer.hmmer.hmmpress(hmms, \"../data/pfam/\")\n",
    "\n",
    "    # Ensure input_file has .fasta extension\n",
    "    if not input_file.endswith('.fasta'):\n",
    "        input_file = f\"{os.path.splitext(input_file)[0]}.fasta\"\n",
    "    # Ensure output_file has .domtblout extension\n",
    "    if not output_file.endswith('.domtblout'):\n",
    "        output_file = f\"{os.path.splitext(output_file)[0]}.domtblout\"\n",
    "\n",
    "    # amino acid alphabet and prefetched inputs\n",
    "    aa = pyhmmer.easel.Alphabet.amino()\n",
    "    optimized_profiles = list(pyhmmer.plan7.HMMPressedFile(hmmdb))\n",
    "    targets = pyhmmer.plan7.OptimizedProfileBlock(\n",
    "        aa, optimized_profiles) if prefetching else pyhmmer.plan7.HMMFile(\"../data/pfam/.h3m\")\n",
    "\n",
    "    # HMMscan execution with or without save_out\n",
    "    with pyhmmer.easel.SequenceFile(input_file, digital=True) as seqs:\n",
    "        if save_out:\n",
    "            with open(output_file, \"wb\", encoding=\"utf-8\") as dst:\n",
    "                for i, hits in enumerate(\n",
    "                    pyhmmer.hmmer.hmmscan(\n",
    "                        seqs, targets, cpus=cpu, E=eval_con)):\n",
    "                    hits.write(dst, format=\"domains\", header=i == 0)\n",
    "        else:\n",
    "            all_hits = pyhmmer.hmmscan(seqs, targets, cpus=cpu, E=eval_con)\n",
    "\n",
    "    return all_hits if not save_out else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing\n",
    "\n",
    "# read df \n",
    "df_sample = pd.read_csv(\"learn2therm_sample_50k_exploration.csv\", index_col=0)\n",
    "\n",
    "# split the database into corresponding thermo and meso lists\n",
    "meso_seq_db = df_sample[[\"meso_index\", \"m_protein_seq\"]]\n",
    "thermo_seq_db = df_sample[[\"thermo_index\", \"t_protein_seq\"]]\n",
    "\n",
    "# make the corresponding index the dataframe index and only sample a 50 sequences\n",
    "meso_seq_list = meso_seq_db.set_index(\"meso_index\").iloc[:50]\n",
    "meso_seq_list.index.name = None\n",
    "meso_seq_list.rename({'m_protein_seq': 'protein_seq'}, axis=\"columns\", inplace=True)\n",
    "\n",
    "thermo_seq_list = thermo_seq_db.set_index(\"thermo_index\").iloc[:50]\n",
    "thermo_seq_list.index.name = None\n",
    "thermo_seq_list.rename({'t_protein_seq': 'protein_seq'}, axis=\"columns\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hmmer(meso_seq_list, \"meso_input\", PFAM_PATH, \"meso_output\", cpu=5, prefetching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_hits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_hits\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_hits' is not defined"
     ]
    }
   ],
   "source": [
    "all_hits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I've to work with the run_pyhmmer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash\n",
    "\n",
    "def run_pyhmmer(\n",
    "        hmmdb: str,\n",
    "        input_file: str,\n",
    "        output_file: str,\n",
    "        cpu: int = 4,\n",
    "        prefetching=False,\n",
    "        save_out=False,\n",
    "        eval_con: float = 1e-10,\n",
    "        num_hashes: int = 128\n",
    "        ):\n",
    "    # Create hmms\n",
    "    hmms = pyhmmer.plan7.HMMFile(hmmdb)\n",
    "    # press hmms and store them in the pfam data folder or w/e destination\n",
    "    if not os.path.exists(\n",
    "        os.path.join(\n",
    "            \"../data/pfam/\",\n",
    "            os.path.basename(hmmdb) +\n",
    "            \".h3m\")):\n",
    "        pyhmmer.hmmer.hmmpress(hmms, \"../data/pfam/\")\n",
    "\n",
    "    # Ensure input_file and has .fasta extension\n",
    "    input_file, input_ext = os.path.splitext(input_file)\n",
    "    if input_ext != '.fasta':\n",
    "        input_file += '.fasta'\n",
    "\n",
    "    output_file, output_ext = os.path.splitext(output_file)\n",
    "    if output_ext != '.domtblout':\n",
    "        output_file += '.domtblout'\n",
    "\n",
    "\n",
    "    # amino acid alphabet and prefetched inputs\n",
    "    aa = pyhmmer.easel.Alphabet.amino()\n",
    "    optimized_profiles = list(pyhmmer.plan7.HMMPressedFile(hmmdb))\n",
    "    targets = pyhmmer.plan7.OptimizedProfileBlock(\n",
    "        aa, optimized_profiles) if prefetching else pyhmmer.plan7.HMMFile(\"../data/pfam/.h3m\")\n",
    "    # minhash dict\n",
    "    minhashes = {}\n",
    "\n",
    "    # HMMscan execution with or without save_out\n",
    "    with pyhmmer.easel.SequenceFile(input_file, digital=True) as seqs:\n",
    "        if save_out:\n",
    "            with open(output_file, \"wb\") as dst:\n",
    "                for i, hits in enumerate(\n",
    "                    pyhmmer.hmmer.hmmscan(\n",
    "                        seqs, targets, cpus=cpu, E=eval_con)):\n",
    "                        hits.write(dst, format=\"domains\", header=i == 0)\n",
    "                        for hit in hits:\n",
    "                            # Get the accession ID\n",
    "                            acc_id = hit.accession\n",
    "\n",
    "                            # Create a MinHash object for the accession ID\n",
    "                            mh = MinHash(num_perm=num_hashes)\n",
    "                            for d in acc_id:\n",
    "                                mh.update(d.to_bytes(1, 'little'))\n",
    "\n",
    "                            # Add the MinHash object to the dictionary\n",
    "                            if acc_id not in minhashes:\n",
    "                                minhashes[acc_id] = mh\n",
    "            return minhashes \n",
    "        else:\n",
    "            all_hits = pyhmmer.hmmer.hmmscan(seqs, targets, cpus=cpu, E=eval_con)\n",
    "            for hits in all_hits:\n",
    "                for hit in hits:\n",
    "                    # Get the accession ID\n",
    "                    acc_id = hit.accession\n",
    "\n",
    "                    # Create a MinHash object for the accession ID\n",
    "                    mh = MinHash(num_perm=num_hashes)\n",
    "                    for d in acc_id:\n",
    "                        mh.update(d.to_bytes(1, 'little'))\n",
    "\n",
    "                    # Add the MinHash object to the dictionary\n",
    "                    if acc_id not in minhashes:\n",
    "                        minhashes[acc_id] = mh\n",
    "\n",
    "            # minhashes is now a dictionary with accession IDs as keys and MinHash objects as values\n",
    "            return minhashes\n",
    "\n",
    "    return minhashes if not save_out else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time with prefetching on: 10.858 seconds\n"
     ]
    }
   ],
   "source": [
    "hmmdb = PFAM_PATH\n",
    "input_file = \"../data/meso_input\"\n",
    "output_file = \"testing3\"\n",
    "\n",
    "# Test with prefetching off\n",
    "# start_time = time.time()\n",
    "# run_pyhmmer(hmmdb, input_file, output_file, cpu=4, prefetching=False)\n",
    "# end_time = time.time()\n",
    "# print(f\"Time with prefetching off: {end_time - start_time:.3f} seconds\")\n",
    "\n",
    "# Test with prefetching on\n",
    "start_time = time.time()\n",
    "run_pyhmmer(hmmdb, input_file, output_file, cpu=4, prefetching=True, save_out=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time with prefetching on: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pyhmmer(\n",
    "        hmmdb: str,\n",
    "        input_file: str,\n",
    "        output_file: str,\n",
    "        cpu: int = 4,\n",
    "        prefetching=False,\n",
    "        save_out=False,\n",
    "        eval_con: float = 1e-10,\n",
    "        num_hashes: int = 128\n",
    "        ):\n",
    "    # Create hmms\n",
    "    hmms = pyhmmer.plan7.HMMFile(hmmdb)\n",
    "    # press hmms and store them in the pfam data folder or w/e destination\n",
    "    if not os.path.exists(\n",
    "        os.path.join(\n",
    "            \"../data/pfam/\",\n",
    "            os.path.basename(hmmdb) +\n",
    "            \".h3m\")):\n",
    "        pyhmmer.hmmer.hmmpress(hmms, \"../data/pfam/\")\n",
    "\n",
    "    # ensure input_file and has .fasta extension\n",
    "    input_file, input_ext = os.path.splitext(input_file)\n",
    "    if input_ext != '.fasta':\n",
    "        input_file += '.fasta'\n",
    "\n",
    "    output_file, output_ext = os.path.splitext(output_file)\n",
    "    if output_ext != '.domtblout':\n",
    "        output_file += '.domtblout'\n",
    "\n",
    "\n",
    "    # amino acid alphabet and prefetched inputs\n",
    "    aa = pyhmmer.easel.Alphabet.amino()\n",
    "    optimized_profiles = list(pyhmmer.plan7.HMMPressedFile(hmmdb))\n",
    "    targets = pyhmmer.plan7.OptimizedProfileBlock(\n",
    "        aa, optimized_profiles) if prefetching else pyhmmer.plan7.HMMFile(\"../data/pfam/.h3m\")\n",
    "    # minhash dict\n",
    "    minhashes = {}\n",
    "\n",
    "    # HMMscan execution with or without save_out\n",
    "    with pyhmmer.easel.SequenceFile(input_file, digital=True) as seqs:\n",
    "        all_hits = pyhmmer.hmmer.hmmscan(seqs, targets, cpus=cpu, E=eval_con)\n",
    "        for hits in all_hits:\n",
    "            for hit in hits:\n",
    "                # get the accession ID\n",
    "                acc_id = hit.accession\n",
    "\n",
    "                # Create a MinHash object for the accession ID\n",
    "                mh = MinHash(num_perm=num_hashes)\n",
    "                for d in acc_id:\n",
    "                    mh.update(d.to_bytes(1, 'little'))\n",
    "\n",
    "                # Add the MinHash object to the dictionary\n",
    "                if acc_id not in minhashes:\n",
    "                    minhashes[acc_id] = mh\n",
    "        if save_out:\n",
    "            with open(output_file, \"wb\") as dst:\n",
    "                for i, hits in enumerate(all_hits):\n",
    "                    hits.write(dst, format=\"domains\", header=i == 0)\n",
    "\n",
    "    return minhashes if not save_out else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validprot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
