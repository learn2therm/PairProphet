{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev-work: working on pyhmmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system dependecies\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# library dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "## biopython\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SearchIO\n",
    "\n",
    "# pyhmmer\n",
    "import pyhmmer\n",
    "\n",
    "# local dependencies/utils\n",
    "\n",
    "## Paths\n",
    "PFAM_PATH = Path(\"/Users/humoodalanzi/pfam/Pfam-A.hmm\")\n",
    "ID_DB_PATH = Path(\"/Users/humoodalanzi/pfam/proteins_id.zip\")\n",
    "DATA_PATH = Path(\"../data/\")\n",
    "OUT_PATH = Path(\"../data/pfam/\")\n",
    "#probably need path of unit tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For references on how to use the pyhmmer API, check this [link](https://pyhmmer.readthedocs.io/en/stable/api/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Press pfam HMM into db for speed purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pyhmmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19632"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create hmms\n",
    "hmms = pyhmmer.plan7.HMMFile(PFAM_PATH)\n",
    "# press hmms and store them in the pfam data folder\n",
    "pyhmmer.hmmer.hmmpress(hmms, \"../data/pfam/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like my HMMER3 code, this should be the number of HMMs inside my pfam db"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An aside; to create FASTA files\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I still need my read_seq function from previous rounds of development. The reason why I didn't directly import it is because I am using a different enviroment for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seq(lists: pd.core.frame.DataFrame, inputname: str = \"input\"):\n",
    "    \"\"\"\n",
    "    Returns a list of SeqRecord objects and creates a corresponding input Fasta of them\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    list : pandas.core.frame.DataFrame\n",
    "        a dataframe with string amino acid sequences in a 'seq' column\n",
    "    input name : str, default = 'input'\n",
    "        a name for the input fasta file\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    ------------\n",
    "    file : TextIOWrapper\n",
    "        the input fasta file created from the list of SeqRecord objects\n",
    "\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError : \n",
    "        if the input dataframe is empty\n",
    "    AttributeError :\n",
    "        if any of the sequences are invalid\n",
    "    \"\"\"\n",
    "    # check if input is empty\n",
    "    if lists.empty:\n",
    "        raise ValueError(\"Input dataframe is empty\")\n",
    "    \n",
    "    # check if sequences are valid\n",
    "    for seq in lists['protein_seq']:\n",
    "        try:\n",
    "            Seq(seq)\n",
    "        except:\n",
    "            raise AttributeError(\"Invalid sequence\")\n",
    "\n",
    "    # function    \n",
    "    records = []\n",
    "    for index, seq in lists.itertuples():\n",
    "        try:\n",
    "            record = SeqRecord(Seq(seq), id=str(index))\n",
    "            records.append(record)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(f\"Invalid sequence: {seq}\")\n",
    "    \n",
    "    # raise error if seq not valid\n",
    "    if not records:\n",
    "        raise AttributeError(\"No valid sequences found in input\")\n",
    "    \n",
    "    with open(f\"{inputname}.fasta\", \"w\") as file:\n",
    "            SeqIO.write(records, file, \"fasta\")\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 0 to 49999\n",
      "Data columns (total 29 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   local_gap_compressed_percent_id        50000 non-null  float64\n",
      " 1   scaled_local_query_percent_id          50000 non-null  float64\n",
      " 2   scaled_local_symmetric_percent_id      50000 non-null  float64\n",
      " 3   query_align_len                        50000 non-null  int64  \n",
      " 4   query_align_cov                        50000 non-null  float64\n",
      " 5   subject_align_len                      50000 non-null  int64  \n",
      " 6   subject_align_cov                      50000 non-null  float64\n",
      " 7   bit_score                              50000 non-null  int64  \n",
      " 8   thermo_index                           50000 non-null  int64  \n",
      " 9   meso_index                             50000 non-null  int64  \n",
      " 10  prot_pair_index                        50000 non-null  int64  \n",
      " 11  meso_protein_int_index                 50000 non-null  int64  \n",
      " 12  thermo_protein_int_index               50000 non-null  int64  \n",
      " 13  taxa_pair_index                        50000 non-null  int64  \n",
      " 14  local_gap_compressed_percent_id_16s    50000 non-null  float64\n",
      " 15  scaled_local_query_percent_id_16s      50000 non-null  float64\n",
      " 16  scaled_local_symmetric_percent_id_16s  50000 non-null  float64\n",
      " 17  query_align_cov_16s                    50000 non-null  float64\n",
      " 18  subject_align_cov_16s                  50000 non-null  float64\n",
      " 19  bit_score_16s                          50000 non-null  float64\n",
      " 20  m_ogt                                  50000 non-null  float64\n",
      " 21  t_ogt                                  50000 non-null  float64\n",
      " 22  ogt_difference                         50000 non-null  float64\n",
      " 23  m_protein_seq                          50000 non-null  object \n",
      " 24  t_protein_seq                          50000 non-null  object \n",
      " 25  m_protein_desc                         50000 non-null  object \n",
      " 26  t_protein_desc                         50000 non-null  object \n",
      " 27  m_protein_len                          50000 non-null  int64  \n",
      " 28  t_protein_len                          50000 non-null  int64  \n",
      "dtypes: float64(14), int64(11), object(4)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sample = pd.read_csv('learn2therm_sample_50k_exploration.csv', index_col=0)\n",
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='../data/thermo_input.fasta' mode='w' encoding='UTF-8'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Meso (+a bit of processing)\n",
    "meso_seq_db2 = df_sample[[\"meso_index\", \"m_protein_seq\"]]\n",
    "meso_seq_list2 = meso_seq_db2.set_index(\"meso_index\").iloc[:100]\n",
    "meso_seq_list2.index.name = None\n",
    "meso_seq_list2.rename({'m_protein_seq': 'protein_seq'}, axis=\"columns\", inplace=True)\n",
    "\n",
    "\n",
    "## Thermo (+ a bit of processing)\n",
    "thermo_seq_db2 = df_sample[[\"thermo_index\", \"t_protein_seq\"]]\n",
    "thermo_seq_list2 = thermo_seq_db2.set_index(\"thermo_index\").iloc[:100]\n",
    "thermo_seq_list2.index.name = None\n",
    "thermo_seq_list2.rename({'t_protein_seq': 'protein_seq'}, axis=\"columns\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# generate meso and thermo files\n",
    "read_seq(meso_seq_list2, \"../data/meso_input\")\n",
    "read_seq(thermo_seq_list2, \"../data/thermo_input\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with pyhmmer proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- hmmscan found 100 hits without prefetching in 5.46 seconds\n"
     ]
    }
   ],
   "source": [
    "with pyhmmer.plan7.HMMFile(\"../data/pfam/\") as hmms:\n",
    "    with pyhmmer.easel.SequenceFile(\"../data/meso_input.fasta\", digital=True) as seqs:\n",
    "        t1 = time.time()\n",
    "        all_hits = list(pyhmmer.hmmer.hmmscan(seqs, hmms, cpus=5, E=1e-10))\n",
    "        totals = len(all_hits)\n",
    "        print(f\"- hmmscan found {totals} hits without prefetching in {time.time() - t1:.3} seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the variable \"all_hits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyhmmer.plan7.TopHits at 0x7f9dbfa9fb40>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = all_hits[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's explore the different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_cython__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__setstate_cython__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'accession',\n",
       " 'best_domain',\n",
       " 'bias',\n",
       " 'description',\n",
       " 'domains',\n",
       " 'dropped',\n",
       " 'duplicate',\n",
       " 'evalue',\n",
       " 'hits',\n",
       " 'included',\n",
       " 'name',\n",
       " 'new',\n",
       " 'pre_score',\n",
       " 'pvalue',\n",
       " 'reported',\n",
       " 'score',\n",
       " 'sum_score']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E',\n",
       " 'T',\n",
       " 'Z',\n",
       " '__add__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'bit_cutoffs',\n",
       " 'block_length',\n",
       " 'compare_ranking',\n",
       " 'copy',\n",
       " 'domE',\n",
       " 'domT',\n",
       " 'domZ',\n",
       " 'incE',\n",
       " 'incT',\n",
       " 'incdomE',\n",
       " 'incdomT',\n",
       " 'included',\n",
       " 'is_sorted',\n",
       " 'long_targets',\n",
       " 'merge',\n",
       " 'query_accession',\n",
       " 'query_name',\n",
       " 'reported',\n",
       " 'searched_models',\n",
       " 'searched_nodes',\n",
       " 'searched_residues',\n",
       " 'searched_sequences',\n",
       " 'sort',\n",
       " 'strand',\n",
       " 'to_msa',\n",
       " 'write']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(all_hits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hits[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got three hits for the first input; interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Sigma70_r2'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.name\n",
    "# correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'PF04542.17'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.accession\n",
    "# that's true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5999653142493426e-19"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.evalue\n",
    "# right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3243507101922078e-23"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.pvalue\n",
    "# this is c-evalue in hmmer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyhmmer.plan7.Domain at 0x148472480>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.best_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_cython__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__setstate_cython__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'alignment',\n",
       " 'bias',\n",
       " 'c_evalue',\n",
       " 'correction',\n",
       " 'env_from',\n",
       " 'env_to',\n",
       " 'envelope_score',\n",
       " 'hit',\n",
       " 'i_evalue',\n",
       " 'included',\n",
       " 'pvalue',\n",
       " 'reported',\n",
       " 'score']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test1.best_domain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "way too much information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E',\n",
       " 'T',\n",
       " 'Z',\n",
       " '__add__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'bit_cutoffs',\n",
       " 'block_length',\n",
       " 'compare_ranking',\n",
       " 'copy',\n",
       " 'domE',\n",
       " 'domT',\n",
       " 'domZ',\n",
       " 'incE',\n",
       " 'incT',\n",
       " 'incdomE',\n",
       " 'incdomT',\n",
       " 'included',\n",
       " 'is_sorted',\n",
       " 'long_targets',\n",
       " 'merge',\n",
       " 'query_accession',\n",
       " 'query_name',\n",
       " 'reported',\n",
       " 'searched_models',\n",
       " 'searched_nodes',\n",
       " 'searched_residues',\n",
       " 'searched_sequences',\n",
       " 'sort',\n",
       " 'strand',\n",
       " 'to_msa',\n",
       " 'write']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test1.hits)\n",
    "# you can move between top hits and hit; very cool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can I save the pyhmmer results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E',\n",
       " 'T',\n",
       " 'Z',\n",
       " '__add__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'bit_cutoffs',\n",
       " 'block_length',\n",
       " 'compare_ranking',\n",
       " 'copy',\n",
       " 'domE',\n",
       " 'domT',\n",
       " 'domZ',\n",
       " 'incE',\n",
       " 'incT',\n",
       " 'incdomE',\n",
       " 'incdomT',\n",
       " 'included',\n",
       " 'is_sorted',\n",
       " 'long_targets',\n",
       " 'merge',\n",
       " 'query_accession',\n",
       " 'query_name',\n",
       " 'reported',\n",
       " 'searched_models',\n",
       " 'searched_nodes',\n",
       " 'searched_residues',\n",
       " 'searched_sequences',\n",
       " 'sort',\n",
       " 'strand',\n",
       " 'to_msa',\n",
       " 'write']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(all_hits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- hmmscan found 100 hits without prefetching in 5.51 seconds\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "Result = collections.namedtuple(\"Result\", [\"name\", \"query\", \"accession\" , \"bitscore\"])\n",
    "\n",
    "results = []\n",
    "with pyhmmer.plan7.HMMFile(\"../data/pfam/\") as hmms:\n",
    "    with pyhmmer.easel.SequenceFile(\"../data/meso_input.fasta\", digital=True) as seqs:\n",
    "        t1 = time.time()\n",
    "        all_hits = list(pyhmmer.hmmer.hmmscan(seqs, hmms, cpus=5, E=1e-10))\n",
    "        totals = len(all_hits)\n",
    "        print(f\"- hmmscan found {totals} hits without prefetching in {time.time() - t1:.3} seconds\")\n",
    "        \n",
    "        # find query\n",
    "        for top_hits in all_hits:\n",
    "            query = top_hits.query_name.decode()\n",
    "        for hit in top_hits:\n",
    "            if hit.included:\n",
    "                results.append(Result(hit.name.decode(), query, hit.accession, hit.score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really inefficent (meomry) I don't like that. Let's see if I can use IOBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"pyhmmer/fileobj/bsd.pxi\", line 107, in pyhmmer.plan7.fopen_obj\n",
      "AttributeError: 'str' object has no attribute 'readable'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/0x/cl_8377x4478rhw2_0zwyxdw0000gn/T/ipykernel_4241/3160972728.py\", line 8, in <module>\n",
      "    top_hits.write('testing',format='domains', header=True)\n",
      "  File \"pyhmmer/plan7.pyx\", line 8011, in pyhmmer.plan7.TopHits.write\n",
      "  File \"pyhmmer/plan7.pyx\", line 8050, in pyhmmer.plan7.TopHits.write\n",
      "  File \"pyhmmer/fileobj/bsd.pxi\", line 118, in pyhmmer.plan7.fopen_obj\n",
      "TypeError: expected `io.IOBase` instance, found str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1049, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 935, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1003, in get_records\n",
      "    lines, first = inspect.getsourcelines(etb.tb_frame)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/inspect.py\", line 1244, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/pyhmmer/lib/python3.11/inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "with pyhmmer.plan7.HMMFile(\"../data/pfam/\") as hmms:\n",
    "    with pyhmmer.easel.SequenceFile(\"../data/meso_input.fasta\", digital=True) as seqs:\n",
    "        t1 = time.time()\n",
    "        all_hits = list(pyhmmer.hmmer.hmmscan(seqs, hmms, cpus=5, E=1e-10))\n",
    "\n",
    "    # write hits to file    \n",
    "    with open(\"testing.txt\", \"w\") as f:\n",
    "        for top_hits in all_hits:\n",
    "            top_hits.write(str(f),format='domains', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pyhmmer(hmm: str, input_file: str, destination:str, cpu: int = 4, prefetching= False, saveout=False):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    # Create hmms\n",
    "    hmms = pyhmmer.plan7.HMMFile(hmm)\n",
    "    # press hmms and store them in the pfam data folder or w/e destination\n",
    "    pyhmmer.hmmer.hmmpress(hmms, destination)\n",
    "\n",
    "    if prefetching is False:\n",
    "        with pyhmmer.plan7.HMMFile(destination) as hmms:\n",
    "            with pyhmmer.easel.SequenceFile(input, digital=True) as seqs:\n",
    "                t1 = time.time()\n",
    "                all_hits = list(pyhmmer.hmmer.hmmscan(seqs, hmms, cpus=cpu, E=1e-10))\n",
    "                totals = len(all_hits)\n",
    "                print(f\"- hmmscan found {totals} hits without prefetching in {time.time() - t1:.3} seconds\")\n",
    "    else:\n",
    "        print(\"TODO\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a wrapper for pyhmmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMMER_run(seqs: pd.core.frame.DataFrame, input_file: str, hmm: str, destination: str, cpu: int = 4, prefetching= False, saveout=False):\n",
    "    \"\"\"\n",
    "    Executes HMMER against pfam/hmm\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    seqs : pandas.core.frame.DataFrame\n",
    "        a dataframe with string amino acid sequences in a 'protein_seq' column\n",
    "        (has to be processed in a certain way)\n",
    "    input_filename : str\n",
    "        A file name for the input of the transformed seq to FASTA\n",
    "    pfam_path : str\n",
    "        path of the HMMER/pfam db\n",
    "    input_filename_with_ext : str\n",
    "        A file name for the input FASTA has to include the ext. FASTA\n",
    "    output_filename_with_ext : str\n",
    "        output file name perferred extension is domtblout\n",
    "    cpu : 4\n",
    "        number of cpus for i/o\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    file : TextIOWrapper (Input fasta file)\n",
    "        the input fasta file created from the list of SeqRecord objects\n",
    "    \n",
    "    (Optional) \n",
    "    file : TextIOWrapper (Output domtblout file)\n",
    "        an output domtblout file of the HMMER/pfam results\n",
    "    \"\"\"\n",
    "    # generate meso and thermo files\n",
    "    read_seq(seqs, input_file)\n",
    "\n",
    "    # place files into HMMER/pfam\n",
    "    run_pyhmmer(\n",
    "        hmm,\n",
    "        input_file,\n",
    "        destination,\n",
    "        cpu)\n",
    "\n",
    "def read_seq(lists: pd.core.frame.DataFrame, inputname: str = \"input\"):\n",
    "    \"\"\"\n",
    "    Returns a list of SeqRecord objects and creates a corresponding input Fasta of them\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    list : pandas.core.frame.DataFrame\n",
    "        a dataframe with string amino acid sequences in a 'seq' column\n",
    "    input name : str, default = 'input'\n",
    "        a name for the input fasta file\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    ------------\n",
    "    file : TextIOWrapper\n",
    "        the input fasta file created from the list of SeqRecord objects\n",
    "\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError : \n",
    "        if the input dataframe is empty\n",
    "    AttributeError :\n",
    "        if any of the sequences are invalid\n",
    "    \"\"\"\n",
    "    # check if input is empty\n",
    "    if lists.empty:\n",
    "        raise ValueError(\"Input dataframe is empty\")\n",
    "    \n",
    "    # check if sequences are valid\n",
    "    for seq in lists['protein_seq']:\n",
    "        try:\n",
    "            Seq(seq)\n",
    "        except:\n",
    "            raise AttributeError(\"Invalid sequence\")\n",
    "\n",
    "    # function    \n",
    "    records = []\n",
    "    for index, seq in lists.itertuples():\n",
    "        try:\n",
    "            record = SeqRecord(Seq(seq), id=str(index))\n",
    "            records.append(record)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(f\"Invalid sequence: {seq}\")\n",
    "    \n",
    "    # raise error if seq not valid\n",
    "    if not records:\n",
    "        raise AttributeError(\"No valid sequences found in input\")\n",
    "    \n",
    "    with open(f\"{inputname}.fasta\", \"w\") as file:\n",
    "            SeqIO.write(records, file, \"fasta\")\n",
    "    return file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pre-fetching ought to be an argument \n",
    "- re-make the whole component \n",
    "    - test it out on small bit\n",
    "- time a 100 seq as a resource test with 1 CPU {embarrsibgly parrallel}\n",
    "- redo with 10 CPUS; compare speed\n",
    "    - analysis plot\n",
    "\n",
    "\n",
    "HMMER(path/to/seqs, path/to/hmms, cpus= int, perfetch=boolean, saveOut=boolean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
