{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBList\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "import asyncio\n",
    "import httpx\n",
    "import nest_asyncio\n",
    "\n",
    "import duckdb as db\n",
    "import numpy as np\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meso_pid</th>\n",
       "      <th>thermo_pid</th>\n",
       "      <th>meso_pdb</th>\n",
       "      <th>thermo_pdb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P9WJA3</td>\n",
       "      <td>A0A1M6N9Z6</td>\n",
       "      <td>1Y5H</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I6XFS7</td>\n",
       "      <td>A0A1M6WSV2</td>\n",
       "      <td>6M1C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q65EQ1</td>\n",
       "      <td>A0A521F3Z2</td>\n",
       "      <td>6NKG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F5HRS7</td>\n",
       "      <td>A0A2T0LBQ2</td>\n",
       "      <td>7QH4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P9WHM1</td>\n",
       "      <td>C7MUW2</td>\n",
       "      <td>3LP6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A0A4Z0GXN3</td>\n",
       "      <td>A0A1G7W5M9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>G4H893</td>\n",
       "      <td>A0A1W6VMF1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A0A120GMI5</td>\n",
       "      <td>Q5L0I9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>A0A4V2YRI4</td>\n",
       "      <td>A0A3N2GW27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A0A3D9URX8</td>\n",
       "      <td>A0A3N2GYN3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meso_pid  thermo_pid meso_pdb  thermo_pdb\n",
       "0       P9WJA3  A0A1M6N9Z6     1Y5H         NaN\n",
       "1       I6XFS7  A0A1M6WSV2     6M1C         NaN\n",
       "2       Q65EQ1  A0A521F3Z2     6NKG         NaN\n",
       "3       F5HRS7  A0A2T0LBQ2     7QH4         NaN\n",
       "4       P9WHM1      C7MUW2     3LP6         NaN\n",
       "..         ...         ...      ...         ...\n",
       "95  A0A4Z0GXN3  A0A1G7W5M9      NaN         NaN\n",
       "96      G4H893  A0A1W6VMF1      NaN         NaN\n",
       "97  A0A120GMI5      Q5L0I9      NaN         NaN\n",
       "98  A0A4V2YRI4  A0A3N2GW27      NaN         NaN\n",
       "99  A0A3D9URX8  A0A3N2GYN3      NaN         NaN\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./pair_sample.csv', index_col=0)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_aff(session, url, filename):\n",
    "    try:\n",
    "        response = await session.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded file: {filename}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to download file: {filename}. Status code: {response.status_code}\")\n",
    "            return False\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Error while downloading file: {filename}. Exception: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "async def download_af(row, u_column, pdb_dir):\n",
    "    uniprot_id = getattr(row, u_column)\n",
    "    url = f'https://alphafold.ebi.ac.uk/files/AF-{uniprot_id}-F1-model_v4.pdb'\n",
    "    filename = f'{pdb_dir}/{uniprot_id}.pdb'\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        success = await download_aff(client, url, filename)\n",
    "        return success\n",
    "\n",
    "def run_download_af_all(df, pdb_column, u_column, pdb_dir):\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    async def download_af_all():\n",
    "        tasks = []\n",
    "        success_count = 0\n",
    "\n",
    "        if not os.path.exists(pdb_dir):\n",
    "            os.makedirs(pdb_dir)\n",
    "\n",
    "        for row in df.itertuples(index=False):\n",
    "            if pd.isna(getattr(row, pdb_column)):\n",
    "                task = asyncio.create_task(download_af(row, u_column, pdb_dir))\n",
    "                tasks.append(task)\n",
    "\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        success_count = sum(results)\n",
    "\n",
    "        print(f\"Successfully downloaded {success_count} files out of {len(df)}\")\n",
    "\n",
    "    asyncio.run(download_af_all())\n",
    "\n",
    "def download_pdb(df, pdb_column, pdb_dir):\n",
    "    pdbl = PDBList()\n",
    "    for i, row in df.iterrows():\n",
    "        pdb_id = row[pdb_column]\n",
    "        if not pd.isna(pdb_id):  # check for NaN value in PDB IDs column\n",
    "            pdbl.retrieve_pdb_file(pdb_id, pdir=pdb_dir, file_format='pdb')\n",
    "            file_path = os.path.join(pdb_dir, f'pdb{pdb_id.lower()}.ent')\n",
    "            if os.path.exists(file_path):\n",
    "                os.rename(file_path, os.path.join(pdb_dir, f'{pdb_id}.pdb'))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "def download_structure(df, pdb_column, u_column, pdb_dir):\n",
    "    start_time = time.time()  # Start measuring time\n",
    "    if not os.path.exists(pdb_dir):\n",
    "        os.makedirs(pdb_dir)\n",
    "    download_pdb(df, pdb_column, pdb_dir)    \n",
    "    run_download_af_all(df, pdb_column, u_column, pdb_dir)\n",
    "    end_time = time.time()  # Stop measuring time\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time} seconds\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat_dict(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_values.append({'pair_id': row['pair_id'], 'p_value': np.nan})\n",
    "            continue\n",
    "\n",
    "        # Set the FATCAT command and its arguments\n",
    "        cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "        \n",
    "        # Run the FATCAT command and capture the output\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "\n",
    "        # Find the line containing the p-value\n",
    "        p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "        # Extract the p-value and convert it to numeric value\n",
    "        p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_values.append({'pair_id': row['pair_id'], 'p_value': 1})\n",
    "        else:\n",
    "            p_values.append({'pair_pid': row['pair_pid'], 'p_value': 0})\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db.connect(\"./pairpro_50k.db\")\n",
    "df = conn.execute(\"\"\"SELECT thermo_pid, meso_pid, thermo_pdb, meso_pdb, pair_id FROM pairpro.final LIMIT 10000\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fatcat(p1_file, p2_file, pdb_dir):\n",
    "    # Set the FATCAT command and its arguments\n",
    "    cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "\n",
    "    # Run the FATCAT command and capture the output\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    output = result.stdout\n",
    "\n",
    "    # Find the line containing the p-value\n",
    "    p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "    # Extract the p-value and convert it to a numeric value\n",
    "    p_value = float(p_value_line.split()[1])\n",
    "\n",
    "    return p_value\n",
    "\n",
    "def run_fatcat_dict_2(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for index, row in df.iterrows():\n",
    "            if not pd.isna(row['meso_pdb']):\n",
    "                p1 = row['meso_pdb']\n",
    "            else:\n",
    "                p1 = row['meso_pid']\n",
    "\n",
    "            if not pd.isna(row['thermo_pdb']):\n",
    "                p2 = row['thermo_pdb']\n",
    "            else:\n",
    "                p2 = row['thermo_pid']\n",
    "\n",
    "            # Check if the structure files exist in the 'checking' folder\n",
    "            p1_file = f'{p1}.pdb'\n",
    "            p2_file = f'{p2}.pdb'\n",
    "            if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "                # Assign NaN as the p-value instead of dropping the row\n",
    "                p_values.append({'pair_id': row['pair_id'], 'p_value': np.nan})\n",
    "                continue\n",
    "\n",
    "            # Submit the comparison task to the executor\n",
    "            future = executor.submit(compare_fatcat, p1_file, p2_file, pdb_dir)\n",
    "            futures.append((future, row['pair_id']))\n",
    "\n",
    "        # Process the completed tasks and extract the p-values\n",
    "        for future, pair_id in futures:\n",
    "            try:\n",
    "                p_value = future.result()\n",
    "                # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "                if p_value < 0.05:\n",
    "                    p_values.append({'pair_id': pair_id, 'p_value': 1})\n",
    "                else:\n",
    "                    p_values.append({'pair_id': pair_id, 'p_value': 0})\n",
    "            except Exception as e:\n",
    "                # Handle exceptions raised during execution\n",
    "                p_values.append({'pair_id': pair_id, 'p_value': np.nan})\n",
    "                print(f\"Error processing pair {pair_id}: {str(e)}\")\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_values.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Set the FATCAT command and its arguments\n",
    "        cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "        \n",
    "        # Run the FATCAT command and capture the output\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "\n",
    "        # Find the line containing the p-value\n",
    "        p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "        # Extract the p-value and convert it to numeric value\n",
    "        p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_values.append(str(1))\n",
    "        else:\n",
    "            p_values.append(str(0))\n",
    "\n",
    "    df.loc[:, 'p_value'] = p_values  # Use .loc to set the 'p_value' column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat_dict_2(df, pdb_dir, conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if the 'p_value' column exists in the table\n",
    "    cursor.execute(\"PRAGMA table_info(pairpro.final)\")\n",
    "    columns = cursor.fetchall()\n",
    "    if (\"p_value\",) not in columns:\n",
    "        # Add the 'p_value' column to the table\n",
    "        cursor.execute(\"ALTER TABLE pairpro.final ADD COLUMN p_value REAL\")\n",
    "        conn.commit()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_value = np.nan\n",
    "        else:\n",
    "            # Set the FATCAT command and its arguments\n",
    "            cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "            \n",
    "            # Run the FATCAT command and capture the output\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            output = result.stdout\n",
    "\n",
    "            # Find the line containing the p-value\n",
    "            p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "            # Extract the p-value and convert it to a numeric value\n",
    "            p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if the p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_value = 1\n",
    "        else:\n",
    "            p_value = 0\n",
    "        \n",
    "        pair_id = row['pair_id']\n",
    "\n",
    "        # Update the database with the extracted p-value\n",
    "        cursor.execute(f\"UPDATE pairpro.final SET p_value = {p_value} WHERE pair_id = {pair_id}\")\n",
    "\n",
    "    # Commit the changes\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
