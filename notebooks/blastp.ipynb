{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBList\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import ssl\n",
    "\n",
    "import asyncio\n",
    "import httpx\n",
    "import nest_asyncio\n",
    "\n",
    "import duckdb as db\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_aff(session, url, filename):\n",
    "    \"\"\"\n",
    "    Downloads a file asynchronously using an HTTP session.\n",
    "\n",
    "    Args:\n",
    "        session (httpx.AsyncClient): An HTTP session for making requests.\n",
    "        url (str): The URL of the file to download.\n",
    "        filename (str): The name of the file to save.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file is successfully downloaded, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = await session.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded file: {filename}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to download file: {filename}. Status code: {response.status_code}\")\n",
    "            return False\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Error while downloading file: {filename}. Exception: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "async def download_af(row, u_column, pdb_dir):\n",
    "    \"\"\"\n",
    "    Downloads AlphaFold files for a given row asynchronously.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): The row containing the data for the download.\n",
    "        u_column (str): The column name for the UniProt ID.\n",
    "        pdb_dir (str): The directory to save the downloaded files.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the download is successful, False otherwise.\n",
    "    \"\"\"\n",
    "    uniprot_id = getattr(row, u_column)\n",
    "    url = f'https://alphafold.ebi.ac.uk/files/AF-{uniprot_id}-F1-model_v4.pdb'\n",
    "    filename = f'{pdb_dir}/{uniprot_id}.pdb'\n",
    "\n",
    "    async with httpx.AsyncClient(verify=False) as client:  # Disable SSL certificate verification\n",
    "        success = await download_aff(client, url, filename)\n",
    "        return success\n",
    "\n",
    "def run_download_af_all(df, pdb_column, u_column, pdb_dir):\n",
    "    \"\"\"\n",
    "    Runs the asynchronous download of AlphaFold files for all rows in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data for the downloads.\n",
    "        pdb_column (str): The column name for the PDB ID.\n",
    "        u_column (str): The column name for the UniProt ID.\n",
    "        pdb_dir (str): The directory to save the downloaded files.\n",
    "    \n",
    "    Returns:\n",
    "        files: pdb files containing structural information.\n",
    "    \"\"\"\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    async def download_af_all():\n",
    "        tasks = []\n",
    "        success_count = 0\n",
    "\n",
    "        if not os.path.exists(pdb_dir):\n",
    "            os.makedirs(pdb_dir)\n",
    "\n",
    "        for row in df.itertuples(index=False):\n",
    "            if pd.isna(getattr(row, pdb_column)):\n",
    "                task = asyncio.create_task(download_af(row, u_column, pdb_dir))\n",
    "                tasks.append(task)\n",
    "\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        success_count = sum(results)\n",
    "\n",
    "        print(f\"Successfully downloaded {success_count} files out of {len(df)}\")\n",
    "\n",
    "    asyncio.run(download_af_all())\n",
    "\n",
    "def download_pdb(df, pdb_column, pdb_dir):\n",
    "    \"\"\"\n",
    "    Downloads PDB files for the given DataFrame based on PDB IDs.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the PDB IDs.\n",
    "        pdb_column (str): The column name for the PDB ID.\n",
    "        pdb_dir (str): The directory to save the downloaded files.\n",
    "    \n",
    "    Returns: pdb files containing structural information.\n",
    "    \"\"\"\n",
    "    pdbl = PDBList()\n",
    "    pdbs = df[pdb_column].dropna().unique()\n",
    "    for p in pdbs:\n",
    "        pdbl.retrieve_pdb_file(p, pdir=pdb_dir, file_format='pdb')\n",
    "        file_path = os.path.join(pdb_dir, f'pdb{p.lower()}.ent')\n",
    "        if os.path.exists(file_path):\n",
    "            os.rename(file_path, os.path.join(pdb_dir, f'{p}.pdb'))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def download_structure(df, pdb_column, u_column, pdb_dir):\n",
    "    \"\"\"\n",
    "    Downloads structure files for a DataFrame using AlphaFold and PDB.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data for the downloads.\n",
    "        pdb_column (str): The column name for the PDB ID.\n",
    "        u_column (str): The column name for the UniProt ID.\n",
    "        pdb_dir (str): The directory to save the downloaded files.\n",
    "\n",
    "    Returns: pdb files containing structural information.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start measuring time\n",
    "    if not os.path.exists(pdb_dir):\n",
    "        os.makedirs(pdb_dir)\n",
    "    download_pdb(df, pdb_column, pdb_dir)    \n",
    "    run_download_af_all(df, pdb_column, u_column, pdb_dir)\n",
    "    end_time = time.time()  # Stop measuring time\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time} seconds\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fatcat(p1_file, p2_file, pdb_dir, pair_id):\n",
    "    # Set the FATCAT command and its arguments\n",
    "    cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "\n",
    "    # Run the FATCAT command and capture the output\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    output = result.stdout\n",
    "\n",
    "    # Find the line containing the p-value\n",
    "    p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "    # Extract the p-value and convert it to a numeric value\n",
    "    p_value = float(p_value_line.split()[1])\n",
    "\n",
    "    # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "    if p_value < 0.05:\n",
    "        return {'pair_id': pair_id, 'p_value': 1}\n",
    "    else:\n",
    "        return {'pair_id': pair_id, 'p_value': 0}\n",
    "\n",
    "def process_row(row, pdb_dir):\n",
    "    if not pd.isna(row['meso_pdb']):\n",
    "        p1 = row['meso_pdb']\n",
    "    else:\n",
    "        p1 = row['meso_pid']\n",
    "\n",
    "    if not pd.isna(row['thermo_pdb']):\n",
    "        p2 = row['thermo_pdb']\n",
    "    else:\n",
    "        p2 = row['thermo_pid']\n",
    "\n",
    "    # Check if the structure files exist in the 'checking' folder\n",
    "    p1_file = f'{p1}.pdb'\n",
    "    p2_file = f'{p2}.pdb'\n",
    "    if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "        # Assign NaN as the p-value instead of dropping the row\n",
    "        return None\n",
    "\n",
    "    return compare_fatcat(p1_file, p2_file, pdb_dir, row['pair_id'])\n",
    "\n",
    "def run_fatcat_dict_job(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    # Parallelize the execution of the function using joblib\n",
    "    p_values = Parallel(n_jobs=-1)(delayed(process_row)(row, pdb_dir) for _, row in df.iterrows())\n",
    "\n",
    "    # Filter out None values\n",
    "    p_values = [p_value for p_value in p_values if p_value is not None]\n",
    "\n",
    "    with open('output.csv', 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=['pair_id', 'p_value'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(p_values)\n",
    "    return 'output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meso_pid</th>\n",
       "      <th>thermo_pid</th>\n",
       "      <th>meso_pdb</th>\n",
       "      <th>thermo_pdb</th>\n",
       "      <th>pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Q81IG4</td>\n",
       "      <td>A0A1I3UXR9</td>\n",
       "      <td>1YQH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q8Y6Y9</td>\n",
       "      <td>A0A087LCG0</td>\n",
       "      <td>8A63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Q9I5C9</td>\n",
       "      <td>A0A840UQH5</td>\n",
       "      <td>3UMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A0A063XEI0</td>\n",
       "      <td>A0A090J3Q8</td>\n",
       "      <td>7QGU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>A0A7W6BCG0</td>\n",
       "      <td>A0A2S5JGT3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      meso_pid  thermo_pid meso_pdb  thermo_pdb  pair_id\n",
       "29      Q81IG4  A0A1I3UXR9     1YQH         NaN     7521\n",
       "6       Q8Y6Y9  A0A087LCG0     8A63         NaN     1025\n",
       "34      Q9I5C9  A0A840UQH5     3UMC         NaN     2418\n",
       "27  A0A063XEI0  A0A090J3Q8     7QGU         NaN     4792\n",
       "58  A0A7W6BCG0  A0A2S5JGT3      NaN         NaN     2308"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('pair_sample.csv')\n",
    "df_sample = df_test.sample(5)\n",
    "df_sample = df_sample.drop(columns=['Unnamed: 0'])\n",
    "df_sample['pair_id'] = np.random.randint(1000, 9999, size=len(df_sample))\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDB structure '1yqh'...\n",
      "Downloading PDB structure '8a63'...\n",
      "Downloading PDB structure '3umc'...\n",
      "Downloading PDB structure '7qgu'...\n",
      "Desired structure doesn't exist\n",
      "Downloaded file: af/A0A7W6BCG0.pdb\n",
      "Successfully downloaded 1 files out of 5\n",
      "Execution time: 2.5884745121002197 seconds\n",
      "Downloaded file: af/A0A087LCG0.pdb\n",
      "Downloaded file: af/A0A1I3UXR9.pdb\n",
      "Downloaded file: af/A0A090J3Q8.pdb\n",
      "Downloaded file: af/A0A840UQH5.pdb\n",
      "Downloaded file: af/A0A2S5JGT3.pdb\n",
      "Successfully downloaded 5 files out of 5\n",
      "Execution time: 0.5814106464385986 seconds\n"
     ]
    }
   ],
   "source": [
    "download_structure(df_sample, 'meso_pdb', 'meso_pid', 'af')\n",
    "download_structure(df_sample, 'thermo_pdb', 'thermo_pid', 'af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_fatcat_dict_job(df_sample, 'af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db.connect('pairpro_50k.db')\n",
    "df = conn.execute('SELECT pair_id, thermo_pid, thermo_pdb, meso_pid, meso_pdb FROM pairpro.final USING SAMPLE 2').fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: af/I3CKA5.pdb\n",
      "Downloaded file: af/A0A4R2LDN2.pdb\n",
      "Successfully downloaded 2 files out of 2\n",
      "Execution time: 0.748706579208374 seconds\n",
      "Downloaded file: af/A0A1I2ISF5.pdb\n",
      "Downloaded file: af/A0A1I2JES9.pdb\n",
      "Successfully downloaded 2 files out of 2\n",
      "Execution time: 0.16399455070495605 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_structure(df, 'meso_pdb', 'meso_pid', 'af')\n",
    "download_structure(df, 'thermo_pdb', 'thermo_pid', 'af')\n",
    "run_fatcat_dict_job(df, 'af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection at 0x7f5a58bc1430>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = 'pairpro'\n",
    "conn.execute(\"\"\"CREATE OR REPLACE TEMP TABLE structure_results AS SELECT * \n",
    "               FROM read_csv_auto('output.csv', HEADER=TRUE)\"\"\")\n",
    "conn.execute(f\"\"\"ALTER TABLE pairpro.final ADD COLUMN structure_match INT\"\"\")\n",
    "conn.execute(f\"\"\"UPDATE pairpro.final AS f\n",
    "SET structure_match = structure.p_value::INT\n",
    "FROM structure_results AS structure\n",
    "WHERE structure.pair_id = f.pair_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thermo_pid</th>\n",
       "      <th>meso_pid</th>\n",
       "      <th>local_gap_compressed_percent_id</th>\n",
       "      <th>scaled_local_query_percent_id</th>\n",
       "      <th>scaled_local_symmetric_percent_id</th>\n",
       "      <th>local_E_value</th>\n",
       "      <th>query_align_start</th>\n",
       "      <th>query_align_end</th>\n",
       "      <th>subject_align_end</th>\n",
       "      <th>subject_align_start</th>\n",
       "      <th>...</th>\n",
       "      <th>meso_taxid</th>\n",
       "      <th>m_ogt</th>\n",
       "      <th>t_ogt</th>\n",
       "      <th>ogt_difference</th>\n",
       "      <th>m_protein_seq</th>\n",
       "      <th>t_protein_seq</th>\n",
       "      <th>meso_pdb</th>\n",
       "      <th>thermo_pdb</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>structure_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A1I2JES9</td>\n",
       "      <td>I3CKA5</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.554839</td>\n",
       "      <td>0.562092</td>\n",
       "      <td>7.550000e-59</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1022</td>\n",
       "      <td>29.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>MFHCVLHQPEIPPNTGNVIRLCANTQVQLHLIHPLGFSLDDKRMRR...</td>\n",
       "      <td>MFHVALYQPEIPPNTGNIIRLCANTGAQLHLIHPLGFQLTDKALRR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A1I2ISF5</td>\n",
       "      <td>A0A4R2LDN2</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>2.850000e-12</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1133106</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MASKILVVDDEPNILLSLEFLMKHAGFQVRTAGDGDAALAAVATEV...</td>\n",
       "      <td>MDKNMRILIVDDFSTMRRIVKNQLADLGYTNTVEADDGKAAWPILQ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   thermo_pid    meso_pid  local_gap_compressed_percent_id  \\\n",
       "0  A0A1I2JES9      I3CKA5                         0.573333   \n",
       "1  A0A1I2ISF5  A0A4R2LDN2                         0.294118   \n",
       "\n",
       "   scaled_local_query_percent_id  scaled_local_symmetric_percent_id  \\\n",
       "0                       0.554839                           0.562092   \n",
       "1                       0.269231                           0.275591   \n",
       "\n",
       "   local_E_value  query_align_start  query_align_end  subject_align_end  \\\n",
       "0   7.550000e-59                  1              150                150   \n",
       "1   2.850000e-12                  6              124                121   \n",
       "\n",
       "   subject_align_start  ...  meso_taxid  m_ogt  t_ogt  ogt_difference  \\\n",
       "0                    1  ...        1022   29.0   50.0            21.0   \n",
       "1                    4  ...     1133106   30.0   50.0            20.0   \n",
       "\n",
       "                                       m_protein_seq  \\\n",
       "0  MFHCVLHQPEIPPNTGNVIRLCANTQVQLHLIHPLGFSLDDKRMRR...   \n",
       "1  MASKILVVDDEPNILLSLEFLMKHAGFQVRTAGDGDAALAAVATEV...   \n",
       "\n",
       "                                       t_protein_seq  meso_pdb  thermo_pdb  \\\n",
       "0  MFHVALYQPEIPPNTGNIIRLCANTGAQLHLIHPLGFQLTDKALRR...       NaN         NaN   \n",
       "1  MDKNMRILIVDDFSTMRRIVKNQLADLGYTNTVEADDGKAAWPILQ...       NaN         NaN   \n",
       "\n",
       "   pair_id  structure_match  \n",
       "0    14029                1  \n",
       "1     9028                1  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('SELECT * FROM pairpro.final WHERE structure_match IS NOT NULL').fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat_dict(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_values.append({'pair_id': row['pair_id'], 'p_value': np.nan})\n",
    "            continue\n",
    "\n",
    "        # Set the FATCAT command and its arguments\n",
    "        cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "        \n",
    "        # Run the FATCAT command and capture the output\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "\n",
    "        # Find the line containing the p-value\n",
    "        p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "        # Extract the p-value and convert it to numeric value\n",
    "        p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_values.append({'pair_id': row['pair_id'], 'p_value': 1})\n",
    "        else:\n",
    "            p_values.append({'pair_pid': row['pair_pid'], 'p_value': 0})\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fatcat(p1_file, p2_file, pdb_dir):\n",
    "    # Set the FATCAT command and its arguments\n",
    "    cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "\n",
    "    # Run the FATCAT command and capture the output\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    output = result.stdout\n",
    "\n",
    "    # Find the line containing the p-value\n",
    "    p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "    # Extract the p-value and convert it to a numeric value\n",
    "    p_value = float(p_value_line.split()[1])\n",
    "\n",
    "    return p_value\n",
    "\n",
    "def run_fatcat_dict_fut(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for index, row in df.iterrows():\n",
    "            if not pd.isna(row['meso_pdb']):\n",
    "                p1 = row['meso_pdb']\n",
    "            else:\n",
    "                p1 = row['meso_pid']\n",
    "\n",
    "            if not pd.isna(row['thermo_pdb']):\n",
    "                p2 = row['thermo_pdb']\n",
    "            else:\n",
    "                p2 = row['thermo_pid']\n",
    "\n",
    "            # Check if the structure files exist in the 'checking' folder\n",
    "            p1_file = f'{p1}.pdb'\n",
    "            p2_file = f'{p2}.pdb'\n",
    "            if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "                # Assign NaN as the p-value instead of dropping the row\n",
    "                p_values.append({'pair_id': row['pair_id'], 'p_value': np.nan})\n",
    "                continue\n",
    "\n",
    "            # Submit the comparison task to the executor\n",
    "            future = executor.submit(compare_fatcat, p1_file, p2_file, pdb_dir)\n",
    "            futures.append((future, row['pair_id']))\n",
    "\n",
    "        # Process the completed tasks and extract the p-values\n",
    "        for future, pair_id in futures:\n",
    "            try:\n",
    "                p_value = future.result()\n",
    "                # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "                if p_value < 0.05:\n",
    "                    p_values.append({'pair_id': pair_id, 'p_value': 1})\n",
    "                else:\n",
    "                    p_values.append({'pair_id': pair_id, 'p_value': 0})\n",
    "            except Exception as e:\n",
    "                # Handle exceptions raised during execution\n",
    "                p_values.append({'pair_id': pair_id, 'p_value': np.nan})\n",
    "                print(f\"Error processing pair {pair_id}: {str(e)}\")\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_values.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Set the FATCAT command and its arguments\n",
    "        cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "        \n",
    "        # Run the FATCAT command and capture the output\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "\n",
    "        # Find the line containing the p-value\n",
    "        p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "        # Extract the p-value and convert it to numeric value\n",
    "        p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_values.append(str(1))\n",
    "        else:\n",
    "            p_values.append(str(0))\n",
    "\n",
    "    df.loc[:, 'p_value'] = p_values  # Use .loc to set the 'p_value' column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat_dict_2(df, pdb_dir, conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if the 'p_value' column exists in the table\n",
    "    cursor.execute(\"PRAGMA table_info(pairpro.final)\")\n",
    "    columns = cursor.fetchall()\n",
    "    if (\"p_value\",) not in columns:\n",
    "        # Add the 'p_value' column to the table\n",
    "        cursor.execute(\"ALTER TABLE pairpro.final ADD COLUMN p_value REAL\")\n",
    "        conn.commit()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_value = np.nan\n",
    "        else:\n",
    "            # Set the FATCAT command and its arguments\n",
    "            cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "            \n",
    "            # Run the FATCAT command and capture the output\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            output = result.stdout\n",
    "\n",
    "            # Find the line containing the p-value\n",
    "            p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "            # Extract the p-value and convert it to a numeric value\n",
    "            p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if the p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_value = 1\n",
    "        else:\n",
    "            p_value = 0\n",
    "        \n",
    "        pair_id = row['pair_id']\n",
    "\n",
    "        # Update the database with the extracted p-value\n",
    "        cursor.execute(f\"UPDATE pairpro.final SET p_value = {p_value} WHERE pair_id = {pair_id}\")\n",
    "\n",
    "    # Commit the changes\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
