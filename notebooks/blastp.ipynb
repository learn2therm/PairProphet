{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBList\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "import asyncio\n",
    "import httpx\n",
    "import nest_asyncio\n",
    "\n",
    "import duckdb as db\n",
    "import numpy as np\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thermo_pid</th>\n",
       "      <th>meso_pid</th>\n",
       "      <th>thermo_pdb</th>\n",
       "      <th>meso_pdb</th>\n",
       "      <th>pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A2W7RQ16</td>\n",
       "      <td>A0A327VJ32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A2W7RTL2</td>\n",
       "      <td>A0A327VMA9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A2W7RYG8</td>\n",
       "      <td>A0A327W1Z1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A2W7RR29</td>\n",
       "      <td>A0A327W5V0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A2W7RR29</td>\n",
       "      <td>A0A327VM41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>A0A1I2KCV8</td>\n",
       "      <td>A0A4R2LSR5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>A0A1I2KCV8</td>\n",
       "      <td>A0A4R2LUN3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>A0A1I2KCV8</td>\n",
       "      <td>A0A4R2LUB2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A0A1I2KCV8</td>\n",
       "      <td>A0A4R2L1Z0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>A0A1I2KCV8</td>\n",
       "      <td>A0A4R2KWW9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      thermo_pid    meso_pid  thermo_pdb  meso_pdb  pair_id\n",
       "0     A0A2W7RQ16  A0A327VJ32         NaN       NaN     6767\n",
       "1     A0A2W7RTL2  A0A327VMA9         NaN       NaN     6880\n",
       "2     A0A2W7RYG8  A0A327W1Z1         NaN       NaN     7492\n",
       "3     A0A2W7RR29  A0A327W5V0         NaN       NaN     7728\n",
       "4     A0A2W7RR29  A0A327VM41         NaN       NaN     6868\n",
       "...          ...         ...         ...       ...      ...\n",
       "9995  A0A1I2KCV8  A0A4R2LSR5         NaN       NaN     9175\n",
       "9996  A0A1I2KCV8  A0A4R2LUN3         NaN       NaN     9198\n",
       "9997  A0A1I2KCV8  A0A4R2LUB2         NaN       NaN     9194\n",
       "9998  A0A1I2KCV8  A0A4R2L1Z0         NaN       NaN     8571\n",
       "9999  A0A1I2KCV8  A0A4R2KWW9         NaN       NaN     8501\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./chau_test.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def download_aff(session, url, filename):\n",
    "    try:\n",
    "        response = await session.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded file: {filename}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to download file: {filename}. Status code: {response.status_code}\")\n",
    "            return False\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"Error while downloading file: {filename}. Exception: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "async def download_af(row, u_column, pdb_dir):\n",
    "    uniprot_id = getattr(row, u_column)\n",
    "    url = f'https://alphafold.ebi.ac.uk/files/AF-{uniprot_id}-F1-model_v4.pdb'\n",
    "    filename = f'{pdb_dir}/{uniprot_id}.pdb'\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        success = await download_aff(client, url, filename)\n",
    "        return success\n",
    "\n",
    "def run_download_af_all(df, pdb_column, u_column, pdb_dir):\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    async def download_af_all():\n",
    "        tasks = []\n",
    "        success_count = 0\n",
    "\n",
    "        if not os.path.exists(pdb_dir):\n",
    "            os.makedirs(pdb_dir)\n",
    "\n",
    "        for row in df.itertuples(index=False):\n",
    "            if pd.isna(getattr(row, pdb_column)):\n",
    "                task = asyncio.create_task(download_af(row, u_column, pdb_dir))\n",
    "                tasks.append(task)\n",
    "\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        success_count = sum(results)\n",
    "\n",
    "        print(f\"Successfully downloaded {success_count} files out of {len(df)}\")\n",
    "\n",
    "    asyncio.run(download_af_all())\n",
    "\n",
    "def download_pdb(df, pdb_column, pdb_dir):\n",
    "    pdbl = PDBList()\n",
    "    for i, row in df.iterrows():\n",
    "        pdb_id = row[pdb_column]\n",
    "        if not pd.isna(pdb_id):  # check for NaN value in PDB IDs column\n",
    "            pdbl.retrieve_pdb_file(pdb_id, pdir=pdb_dir, file_format='pdb')\n",
    "            file_path = os.path.join(pdb_dir, f'pdb{pdb_id.lower()}.ent')\n",
    "            if os.path.exists(file_path):\n",
    "                os.rename(file_path, os.path.join(pdb_dir, f'{pdb_id}.pdb'))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "def download_structure(df, pdb_column, u_column, pdb_dir):\n",
    "    start_time = time.time()  # Start measuring time\n",
    "    if not os.path.exists(pdb_dir):\n",
    "        os.makedirs(pdb_dir)\n",
    "    download_pdb(df, pdb_column, pdb_dir)    \n",
    "    run_download_af_all(df, pdb_column, u_column, pdb_dir)\n",
    "    end_time = time.time()  # Stop measuring time\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time} seconds\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def compare_fatcat(p1_file, p2_file, pdb_dir, pair_id):\n",
    "    # Set the FATCAT command and its arguments\n",
    "    cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "\n",
    "    # Run the FATCAT command and capture the output\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    output = result.stdout\n",
    "\n",
    "    # Find the line containing the p-value\n",
    "    p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "    # Extract the p-value and convert it to a numeric value\n",
    "    p_value = float(p_value_line.split()[1])\n",
    "\n",
    "    # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "    if p_value < 0.05:\n",
    "        return {'pair_id': pair_id, 'p_value': 1}\n",
    "    else:\n",
    "        return {'pair_id': pair_id, 'p_value': 0}\n",
    "\n",
    "def process_row(row, pdb_dir):\n",
    "    if not pd.isna(row['meso_pdb']):\n",
    "        p1 = row['meso_pdb']\n",
    "    else:\n",
    "        p1 = row['meso_pid']\n",
    "\n",
    "    if not pd.isna(row['thermo_pdb']):\n",
    "        p2 = row['thermo_pdb']\n",
    "    else:\n",
    "        p2 = row['thermo_pid']\n",
    "\n",
    "    # Check if the structure files exist in the 'checking' folder\n",
    "    p1_file = f'{p1}.pdb'\n",
    "    p2_file = f'{p2}.pdb'\n",
    "    if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "        # Assign NaN as the p-value instead of dropping the row\n",
    "        return {'pair_id': row['pair_id'], 'p_value': np.nan}\n",
    "\n",
    "    return compare_fatcat(p1_file, p2_file, pdb_dir, row['pair_id'])\n",
    "\n",
    "def run_fatcat_dict_job(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    # Parallelize the execution of the function using joblib\n",
    "    p_values = Parallel(n_jobs=-1)(delayed(process_row)(row, pdb_dir) for _, row in df.iterrows())\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file: af/A0A6L5BTR4.pdb\n",
      "Downloaded file: af/A0A2W5CT06.pdb\n",
      "Downloaded file: af/A0A1H3G8K0.pdb\n",
      "Successfully downloaded 3 files out of 3\n",
      "Execution time: 0.8319580554962158 seconds\n",
      "Downloaded file: af/A0A1I2I9U7.pdb\n",
      "Downloaded file: af/A0A1I2I9U7.pdb\n",
      "Downloaded file: af/A0A1I2HYV0.pdb\n",
      "Successfully downloaded 3 files out of 3\n",
      "Execution time: 0.12334227561950684 seconds\n"
     ]
    }
   ],
   "source": [
    "df_sample = df_test.sample(3)\n",
    "download_structure(df_sample, 'meso_pdb', 'meso_pid', 'af')\n",
    "download_structure(df_sample, 'thermo_pdb', 'thermo_pid', 'af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pair_id': 3843, 'p_value': 1},\n",
       " {'pair_id': 10999, 'p_value': 1},\n",
       " {'pair_id': 6480, 'p_value': 1}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_fatcat_dict_job(df_sample, 'af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat_dict(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_values.append({'pair_id': row['pair_id'], 'p_value': np.nan})\n",
    "            continue\n",
    "\n",
    "        # Set the FATCAT command and its arguments\n",
    "        cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "        \n",
    "        # Run the FATCAT command and capture the output\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "\n",
    "        # Find the line containing the p-value\n",
    "        p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "        # Extract the p-value and convert it to numeric value\n",
    "        p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_values.append({'pair_id': row['pair_id'], 'p_value': 1})\n",
    "        else:\n",
    "            p_values.append({'pair_pid': row['pair_pid'], 'p_value': 0})\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fatcat(p1_file, p2_file, pdb_dir):\n",
    "    # Set the FATCAT command and its arguments\n",
    "    cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "\n",
    "    # Run the FATCAT command and capture the output\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    output = result.stdout\n",
    "\n",
    "    # Find the line containing the p-value\n",
    "    p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "    # Extract the p-value and convert it to a numeric value\n",
    "    p_value = float(p_value_line.split()[1])\n",
    "\n",
    "    return p_value\n",
    "\n",
    "def run_fatcat_dict_fut(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for index, row in df.iterrows():\n",
    "            if not pd.isna(row['meso_pdb']):\n",
    "                p1 = row['meso_pdb']\n",
    "            else:\n",
    "                p1 = row['meso_pid']\n",
    "\n",
    "            if not pd.isna(row['thermo_pdb']):\n",
    "                p2 = row['thermo_pdb']\n",
    "            else:\n",
    "                p2 = row['thermo_pid']\n",
    "\n",
    "            # Check if the structure files exist in the 'checking' folder\n",
    "            p1_file = f'{p1}.pdb'\n",
    "            p2_file = f'{p2}.pdb'\n",
    "            if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "                # Assign NaN as the p-value instead of dropping the row\n",
    "                p_values.append({'pair_id': row['pair_id'], 'p_value': np.nan})\n",
    "                continue\n",
    "\n",
    "            # Submit the comparison task to the executor\n",
    "            future = executor.submit(compare_fatcat, p1_file, p2_file, pdb_dir)\n",
    "            futures.append((future, row['pair_id']))\n",
    "\n",
    "        # Process the completed tasks and extract the p-values\n",
    "        for future, pair_id in futures:\n",
    "            try:\n",
    "                p_value = future.result()\n",
    "                # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "                if p_value < 0.05:\n",
    "                    p_values.append({'pair_id': pair_id, 'p_value': 1})\n",
    "                else:\n",
    "                    p_values.append({'pair_id': pair_id, 'p_value': 0})\n",
    "            except Exception as e:\n",
    "                # Handle exceptions raised during execution\n",
    "                p_values.append({'pair_id': pair_id, 'p_value': np.nan})\n",
    "                print(f\"Error processing pair {pair_id}: {str(e)}\")\n",
    "\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat(df, pdb_dir):\n",
    "    p_values = []  # List to store the extracted p-values\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_values.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Set the FATCAT command and its arguments\n",
    "        cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "        \n",
    "        # Run the FATCAT command and capture the output\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "\n",
    "        # Find the line containing the p-value\n",
    "        p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "        # Extract the p-value and convert it to numeric value\n",
    "        p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_values.append(str(1))\n",
    "        else:\n",
    "            p_values.append(str(0))\n",
    "\n",
    "    df.loc[:, 'p_value'] = p_values  # Use .loc to set the 'p_value' column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fatcat_dict_2(df, pdb_dir, conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if the 'p_value' column exists in the table\n",
    "    cursor.execute(\"PRAGMA table_info(pairpro.final)\")\n",
    "    columns = cursor.fetchall()\n",
    "    if (\"p_value\",) not in columns:\n",
    "        # Add the 'p_value' column to the table\n",
    "        cursor.execute(\"ALTER TABLE pairpro.final ADD COLUMN p_value REAL\")\n",
    "        conn.commit()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row['meso_pdb']):\n",
    "            p1 = row['meso_pdb']\n",
    "        else:\n",
    "            p1 = row['meso_pid']\n",
    "        \n",
    "        if not pd.isna(row['thermo_pdb']):\n",
    "            p2 = row['thermo_pdb']\n",
    "        else:\n",
    "            p2 = row['thermo_pid']\n",
    "        \n",
    "        # Check if the structure files exist in the 'checking' folder\n",
    "        p1_file = f'{p1}.pdb'\n",
    "        p2_file = f'{p2}.pdb'\n",
    "        if not os.path.exists(os.path.join(pdb_dir, p1_file)) or not os.path.exists(os.path.join(pdb_dir, p2_file)):\n",
    "            # Assign NaN as the p-value instead of dropping the row\n",
    "            p_value = np.nan\n",
    "        else:\n",
    "            # Set the FATCAT command and its arguments\n",
    "            cmd = ['FATCAT', '-p1', p1_file, '-p2', p2_file, '-i', pdb_dir, '-q']\n",
    "            \n",
    "            # Run the FATCAT command and capture the output\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            output = result.stdout\n",
    "\n",
    "            # Find the line containing the p-value\n",
    "            p_value_line = next(line for line in output.split('\\n') if line.startswith(\"P-value\"))\n",
    "\n",
    "            # Extract the p-value and convert it to a numeric value\n",
    "            p_value = float(p_value_line.split()[1])\n",
    "        \n",
    "        # Check if the p-value is less than 0.05 and assign 1 or 0 accordingly\n",
    "        if p_value < 0.05:\n",
    "            p_value = 1\n",
    "        else:\n",
    "            p_value = 0\n",
    "        \n",
    "        pair_id = row['pair_id']\n",
    "\n",
    "        # Update the database with the extracted p-value\n",
    "        cursor.execute(f\"UPDATE pairpro.final SET p_value = {p_value} WHERE pair_id = {pair_id}\")\n",
    "\n",
    "    # Commit the changes\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
